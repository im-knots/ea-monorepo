---
ollama:
  models:
    pull:
      - llama3.2
    run:
      - llama3.2

autoscaling:
  enabled: true
  minReplicas: 1
  maxReplicas: 10
  targetCPUUtilizationPercentage: 80

ingress:
  enabled: true
  className: "nginx"
  annotations:
    kubernetes.io/ingress.class: nginx
  hosts:
    - host: ollama.ea.erulabs.local
      paths:
        - path: /
          pathType: Prefix
